#!/usr/bin/env python
import edd
from edd import util
import edd.logit
import eddlib
import os
import pandas as pa
import sys
import argparse
from logbook import Logger, FileHandler
log = Logger('edd')


def log_parameters(args, argv):
    log.notice('cwd: %s' % os.getcwd())
    log.notice('string args: %s' % ' '.join(argv))
    log.notice('chromosome size file: %s' % args.chrom_size.name)
    log.notice('IP file: %s' % args.ip_bam)
    log.notice('Control file: %s' % args.control_bam)
    log.notice('output dir: %s' % args.output_dir)
    log.notice('number of monte carlo trials: %d' % args.num_trials)
    log.notice('number of processes: %d' % args.nprocs)
    log.notice('pvalue lim: %.3f' % args.plim)
    log.notice('qvalue lim: %.3f' % args.qlim)
    log.notice('negative score scale: %.2f' % args.negative_score_scale)
    log.notice('gap_file  : %s' % args.gap_file.name if args.gap_file else args.gap_file)
    log.notice('drop gaps smaller than: %.2f' % args.drop_gaps_smaller_than)
    if args.replicate:
        log.notice('replicate experiment: \n\tip: %s\n\tctrl: %s' % tuple(args.replicate))
    assert os.path.isfile(args.ip_bam)
    assert os.path.isfile(args.control_bam)

class BamLoader(object):

    def __init__(self, chrom_size_path, bin_size, neg_score_scale):
        self.chrom_size_path = chrom_size_path
        self.bin_size = bin_size
        self.neg_score_scale = neg_score_scale

    def load_bam(self, ip_name, ctrl_name, do_neg_scale=True):
        neg_scale = self.neg_score_scale if do_neg_scale else 1
        odf = edd.load_experiment(self.chrom_size_path, ip_name,
                ctrl_name, self.bin_size,
                use_multiprocessing=True).as_data_frame()
        return edd.logit.ci_for_df(odf, neg_score_scale=neg_scale)

    def __add_bin_scores(self, r1, r2):
        assert len(r1.index) == len(r2.index)
        assert (r1.index == r2.index).all()
        assert (r1.start == r2.start).all()
        common = r1.copy()
        common.score += r2.score
        return common

    def load_replicate_bam(self, r1_ip_name, r1_ctrl_name, 
            r2_ip_name, r2_ctrl_name):
        r1 = self.load_bam(r1_ip_name, r1_ctrl_name, do_neg_scale=False)
        r2 = self.load_bam(r2_ip_name, r2_ctrl_name, do_neg_scale=False)
        df = self.__add_bin_scores(r1, r2)
        df.ix[df.score < 0, 'score'] *= self.neg_score_scale
        return df

def main(args):
    output_name = os.path.basename(args.output_dir.rstrip('/'))
    output_file = os.path.join(args.output_dir, output_name + '_peaks.bed')
    ratio_file = os.path.join(args.output_dir, output_name + '_bin_score.bedgraph')
    bin_size = edd.parse_bin_size_as_single_number(args.bin_size)
    loader = BamLoader(args.chrom_size.name, bin_size, args.negative_score_scale)
    if args.replicate is None:
        df = loader.load_bam(args.ip_bam, args.control_bam)
    else:
        r2_ip, r2_bam = args.replicate
        df = loader.load_replicate_bam(args.ip_bam, args.control_bam,
                    r2_ip, r2_bam)

    df['chrom start end score'.split()].sort(['chrom', 'start']).to_csv(
            ratio_file, sep='\t', index=False, header=False)
    gb = edd.df_as_bins(df, args.gap_file, args.drop_gaps_smaller_than)
    observed_result = gb.max_segments()
    mc_res = eddlib.MonteCarlo.run_simulation(gb.chrom_scores, 
            niter=args.num_trials, nprocs=args.nprocs)
    tester = eddlib.max_segments.IntervalTest(observed_result, mc_res)
    tester.qvalues(below=args.qlim, pval_below=args.plim)
    tester.as_bed(output_file)


if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    parser.add_argument('chrom_size', type=argparse.FileType('r'))
    parser.add_argument('ip_bam')
    parser.add_argument('control_bam')
    parser.add_argument('output_dir')
    parser.add_argument('-s', '--bin-size', default='8kb',
            help='either a range e.g. 1-10, auto or a single number')
    parser.add_argument('--replicate', nargs=2, 
    help='''must be ip.bam and ctrl.bam path for replicate experiment \
            to be merged.''')
    parser.add_argument('-n', '--num-trials', type=int, default=100)
    parser.add_argument('-p', '--nprocs', type=int, default=4)
    parser.add_argument('--qlim', type=float, default=0.05)
    parser.add_argument('--plim', type=float, default=0.05)
    parser.add_argument('-g', '--gap-file', type=argparse.FileType('r'), default=None)
    parser.add_argument('--drop-gaps-smaller-than', type=float, default=1e6)
    parser.add_argument('--negative-score-scale', type=float, default=4)
    # TODO later, if it makes sense at all?
    # perhaps change the scoring function? but how would it know the proportion of scores?
    #parser.add_argument('--max-percentage-enriched-bins', type=float, default=50)
    args = parser.parse_args(sys.argv[1:])
    if not os.path.isdir(args.output_dir):
        os.makedirs(args.output_dir)
    log_file = os.path.join(args.output_dir, 'log.txt')
    log_handler = FileHandler(log_file, level='NOTICE', bubble=True)

    with log_handler.applicationbound():
    #with ipdb.launch_ipdb_on_exception():
        log_parameters(args, sys.argv)
        main(args)
